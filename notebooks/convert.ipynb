{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: implementera hdemucs i flax\n",
    "- gör tester för sub-moduler\n",
    "- testa ladda in modellen direkt via .pt-filen om möjligt\n",
    "  - alternativt spara den i flax-format\n",
    "- mät inferens-speed skillnad vs pytorch\n",
    "  - naivt cpu\n",
    "  - gpu\n",
    "  - compiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchaudio.models import HDemucs\n",
    "\n",
    "state_dict_path = \"models/hdemucs_high_trained.pt\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "sources = [\"drums\", \"bass\", \"other\", \"vocals\"]\n",
    "model = HDemucs(sources=sources, nfft=4096, depth=6)\n",
    "\n",
    "state_dict = torch.load(state_dict_path, weights_only=True)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO = \"./testaudio.wav\"\n",
    "import torchaudio\n",
    "\n",
    "waveform, sample_rate = torchaudio.load(AUDIO, format=\"wav\")\n",
    "\n",
    "ref = waveform.mean(0)\n",
    "waveform_n = (waveform - ref.mean()) / ref.std()\n",
    "\n",
    "waveform_n = waveform_n.unsqueeze(0)\n",
    "print(f\"waveform_n.shape: {waveform_n.shape}\") # (batch, channels, len)\n",
    "result = model(waveform_n)\n",
    "print(f\"result.shape: {result.shape}\") # (batch, sources, channels, length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import test_compare\n",
    "from importlib import reload\n",
    "reload(test_compare)\n",
    "\n",
    "from test_compare import add_print_hook\n",
    "\n",
    "add_print_hook(model)\n",
    "res = model(waveform_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def time_model_forward():\n",
    "    # Run forward pass multiple times and measure execution time\n",
    "    n_runs = 10\n",
    "    times = []\n",
    "    \n",
    "    for _ in tqdm(range(n_runs)):\n",
    "        start = time.perf_counter()\n",
    "        with torch.no_grad():\n",
    "            _ = model(waveform_n) \n",
    "        end = time.perf_counter()\n",
    "        times.append(end - start)\n",
    "    \n",
    "    times = np.array(times)\n",
    "    avg_time = np.mean(times)\n",
    "    std_time = np.std(times)\n",
    "    \n",
    "    print(f\"Average forward pass time: {avg_time:.4f}s ± {std_time:.4f}s\")\n",
    "    print(f\"Min time: {np.min(times):.4f}s\")\n",
    "    print(f\"Max time: {np.max(times):.4f}s\")\n",
    "\n",
    "# Warm up run\n",
    "with torch.no_grad():\n",
    "    _ = model(waveform_n)\n",
    "\n",
    "time_model_forward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(model.freq_emb)\n",
    "pprint(model.freq_emb.scale)\n",
    "\n",
    "model.freq_emb.weight.shape\n",
    "\n",
    "import torch\n",
    "\n",
    "x = torch.ones((512,), dtype=torch.int32)\n",
    "print(x.shape)\n",
    "\n",
    "y = model.freq_emb(x)\n",
    "print(y.shape)\n",
    "\n",
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import demucs\n",
    "reload(demucs)\n",
    "from demucs import ScaledEmbedding\n",
    "\n",
    "from flax import nnx\n",
    "import jax.numpy as jnp\n",
    "\n",
    "scaled_embedding = ScaledEmbedding(3, 3, rngs=nnx.Rngs(0))\n",
    "\n",
    "print(scaled_embedding(jnp.array([0, 1, 2])))\n",
    "\n",
    "print(scaled_embedding.embedding.embedding)\n",
    "\n",
    "scaled_embedding.embedding.embedding = nnx.Param(torch.ones((3, 3)).detach().numpy())\n",
    "\n",
    "print(scaled_embedding.embedding.embedding)\n",
    "\n",
    "print(scaled_embedding(jnp.array([0, 1, 2])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnx.state(scaled_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "reload(utils)\n",
    "from utils import torch_module_to_params\n",
    "\n",
    "params = torch_module_to_params(model.freq_emb)\n",
    "\n",
    "print(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = torch_module_to_params(model)\n",
    "import jax\n",
    "\n",
    "jax.tree_util.tree_map(lambda x: x.shape, model_params)\n",
    "\n",
    "import flax\n",
    "d = flax.traverse_util.unflatten_dict(model_params, sep=\".\")\n",
    "\n",
    "d_jax = jax.tree_util.tree_map(lambda x: x.shape, d)\n",
    "pprint(d_jax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.modeling_flax_pytorch_utils import convert_pytorch_sharded_state_dict_to_flax\n",
    "\n",
    "convert_pytorch_sharded_state_dict_to_flax(model_params, model.params)\n",
    "\n",
    "model_params[\"freq_emb.embedding.embedding\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flax.linen as nn\n",
    "import jax.numpy as jnp\n",
    "from flax import nnx\n",
    "\n",
    "class Foo(nnx.Module):\n",
    "  def __call__(self, x):\n",
    "    return x\n",
    "\n",
    "def my_interceptor1(next_fun, args, kwargs, context):\n",
    "  print('calling my_interceptor1')\n",
    "  return next_fun(*args, **kwargs)\n",
    "\n",
    "foo = Foo()\n",
    "with nn.intercept_methods(my_interceptor1):\n",
    "  _ = foo(jnp.ones([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
