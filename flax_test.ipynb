{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array((), dtype=key<fry>) overlaying:\n",
      "[1797259609 2579123966] Array((), dtype=key<fry>) overlaying:\n",
      "[ 928981903 3453687069]\n",
      "{'params': {'dense': {'bias': Array([0., 0.], dtype=float32),\n",
      "                      'kernel': Array([[-0.51274115, -0.44576186],\n",
      "       [ 0.7367678 , -0.98018515]], dtype=float32)}}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array([-1.1825595,  0.440827 ], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import flax\n",
    "from flax import linen as nn\n",
    "\n",
    "from jax import random, Array\n",
    "from pprint import pprint\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \n",
    "    def setup(self):\n",
    "        self.dense = nn.Dense(features=2) # n output features\n",
    "\n",
    "    def __call__(self, batch: Array):\n",
    "        return self.dense(batch)\n",
    "\n",
    "model = Model()\n",
    "\n",
    "key1, key2 = random.split(random.key(0))\n",
    "print(key1, key2)\n",
    "\n",
    "x = random.normal(key1, (2,))\n",
    "params = model.init(key2, x) # infer model params via test input\n",
    "pprint(params)\n",
    "\n",
    "model.apply(params, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'params': {'dense': {'bias': (2,), 'kernel': (2, 2)}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax\n",
    "\n",
    "jax.tree_util.tree_map(lambda x: x.shape, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([-1.1825595,  0.440827 ], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try compiling model using jit\n",
    "\n",
    "# Make an argument static if it affects how the computation is structured\n",
    "# Keep it dynamic if it's just data flowing through the computation\n",
    "\n",
    "\n",
    "def model_fn(params: dict, batch: Array):\n",
    "    return model.apply(params, batch)\n",
    "\n",
    "model_fn_jit = jax.jit(model_fn)\n",
    "\n",
    "model_fn_jit(params, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-compiled time: 0.8328 seconds\n",
      "JIT-compiled time: 0.0038 seconds\n",
      "Speedup: 219.6x\n"
     ]
    }
   ],
   "source": [
    "# Compare speed of non-compiled vs jit-compiled forward pass\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Number of iterations for timing\n",
    "n_iters = 1000\n",
    "\n",
    "# Time non-compiled version\n",
    "start = time.time()\n",
    "for _ in range(n_iters):\n",
    "    out = model_fn(params, x) \n",
    "end = time.time()\n",
    "non_compiled_time = end - start\n",
    "\n",
    "# Time jit-compiled version \n",
    "# First call to compile\n",
    "_ = model_fn_jit(params, x)\n",
    "\n",
    "start = time.time()\n",
    "for _ in range(n_iters):\n",
    "    out = model_fn_jit(params, x)\n",
    "end = time.time()\n",
    "compiled_time = end - start\n",
    "\n",
    "print(f\"Non-compiled time: {non_compiled_time:.4f} seconds\")\n",
    "print(f\"JIT-compiled time: {compiled_time:.4f} seconds\") \n",
    "print(f\"Speedup: {non_compiled_time/compiled_time:.1f}x\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ lambda ; a:f32[2] b:f32[2,2] c:f32[2]. let\n",
      "    d:f32[2] = dot_general[dimension_numbers=(([0], [0]), ([], []))] c b\n",
      "    e:f32[2] = add d a\n",
      "  in (e,) }\n",
      "{ lambda ; a:f32[2] b:f32[2,2] c:f32[2]. let\n",
      "    d:f32[2] = pjit[\n",
      "      name=model_fn\n",
      "      jaxpr={ lambda ; e:f32[2] f:f32[2,2] g:f32[2]. let\n",
      "          h:f32[2] = dot_general[dimension_numbers=(([0], [0]), ([], []))] g f\n",
      "          i:f32[2] = add h e\n",
      "        in (i,) }\n",
      "    ] a b c\n",
      "  in (d,) }\n"
     ]
    }
   ],
   "source": [
    "# See the JAX program representation before optimization\n",
    "print(jax.make_jaxpr(model_fn)(params, x))\n",
    "\n",
    "# See the optimized version\n",
    "print(jax.make_jaxpr(model_fn_jit)(params, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HloModule jit_model_fn, is_scheduled=true, entry_computation_layout={(f32[2]{0}, f32[2,2]{1,0}, f32[2]{0})->f32[2]{0}}, allow_spmd_sharding_propagation_to_parameters={true,true,true}, allow_spmd_sharding_propagation_to_output={true}\n",
      "\n",
      "%fused_computation (param_0.1: f32[2], param_1.1: f32[2], param_2: f32[2,2]) -> f32[2] {\n",
      "  %param_1.1 = f32[2]{0} parameter(1)\n",
      "  %param_2 = f32[2,2]{1,0} parameter(2)\n",
      "  %dot.0 = f32[2]{0} dot(f32[2]{0} %param_1.1, f32[2,2]{1,0} %param_2), lhs_contracting_dims={0}, rhs_contracting_dims={0}, metadata={op_name=\"jit(model_fn)/jit(main)/Model/dense/dot_general\" source_file=\"/Users/gardberg/dev/cascade/sandbox/hdemucs/.venv/lib/python3.11/site-packages/flax/linen/linear.py\" source_line=271}\n",
      "  %param_0.1 = f32[2]{0} parameter(0)\n",
      "  ROOT %add.0 = f32[2]{0} add(f32[2]{0} %dot.0, f32[2]{0} %param_0.1), metadata={op_name=\"jit(model_fn)/jit(main)/Model/dense/add\" source_file=\"/Users/gardberg/dev/cascade/sandbox/hdemucs/.venv/lib/python3.11/site-packages/flax/linen/linear.py\" source_line=278}\n",
      "}\n",
      "\n",
      "ENTRY %main.6 (Arg_0.1: f32[2], Arg_1.2: f32[2,2], Arg_2.3: f32[2]) -> f32[2] {\n",
      "  %Arg_0.1 = f32[2]{0} parameter(0), metadata={op_name=\"params[\\'params\\'][\\'dense\\'][\\'bias\\']\"}\n",
      "  %Arg_1.2 = f32[2,2]{1,0} parameter(1), metadata={op_name=\"params[\\'params\\'][\\'dense\\'][\\'kernel\\']\"}\n",
      "  %Arg_2.3 = f32[2]{0} parameter(2), metadata={op_name=\"batch\"}\n",
      "  ROOT %dot_add_fusion = f32[2]{0} fusion(f32[2]{0} %Arg_0.1, f32[2]{0} %Arg_2.3, f32[2,2]{1,0} %Arg_1.2), kind=kOutput, calls=%fused_computation, metadata={op_name=\"jit(model_fn)/jit(main)/Model/dense/add\" source_file=\"/Users/gardberg/dev/cascade/sandbox/hdemucs/.venv/lib/python3.11/site-packages/flax/linen/linear.py\" source_line=278}\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the HLO (High Level Optimizer) representation\n",
    "compiled = model_fn_jit.lower(params, x).compile()\n",
    "print(compiled.as_text())  # Print HLO IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([1.2753228 , 0.10528118], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flax import nnx\n",
    "\n",
    "class NnxModel(nnx.Module):\n",
    "    def __init__(self, rngs: nnx.Rngs):\n",
    "        super().__init__()\n",
    "        self.dense = nnx.Linear(2, 2, rngs=rngs)\n",
    "\n",
    "    def forward(self, x: Array) -> Array:\n",
    "        return self.dense(x)\n",
    "\n",
    "rngs = nnx.Rngs(0)\n",
    "model = NnxModel(rngs)\n",
    "\n",
    "model.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
